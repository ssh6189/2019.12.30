######################로지스틱 회귀분석 : 로그 함수를 이용한 오차 구하기#################################
import tensorflow as tf 
import numpy as np

data =[[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]]

x_data = [i[0] for i in data]
y_data = [i[1] for i in data]

#임의의 a, b 값을 변수로 정의
a = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))
b = tf.Variable(tf.random_normal([1], dtype=tf.float64, seed=0))

#시그모이드 함수 방정식 정의
y = 1/ (1+ np.e**(a*x_data+b))

#오차 loss 구하는 함수
loss = -tf.reduce_mean(np.array(y_data)*tf.log(y)+(1-np.array(y_data))*tf.log(1-y))

#학습률 
learning_rate = 0.5

# 오차 rmse 값이 최소인 값 찾는 식 정의
gradient_descent = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)

#텐서플로 이용하여 학습
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())     # 변수들을 메모리에 생성, 초기화
    for step in range(10001):
        sess.run(gradient_descent)
        if step % 1000 == 0:
            print("Epoch: %.f , loss=%.4f,  기울기 a=%.4f, 절편 b= %.4f" % (step, sess.run(loss), sess.run(a), sess.run(b))